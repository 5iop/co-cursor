\section{Related Work}\label{sec:relwk}

% 本章将介绍现有的CAPTCHA技术方案和生成式人工智能的研究现状，用于提供DMTG的知识基础和对比方法。
This section will present the current state of research on existing CAPTCHA technology schemes and GAI, which provide the knowledge base and comparison methodology for DMTG.

\subsection{CAPTCHA and Deceivers}\label{sec:relwk-captcha}

Existing CAPTCHA \cite{CAPTCHA} can be divided into four basic categories: text-based, image-based, audio-based and user behavior-based. Text-based CAPTCHA verifies whether the user has entered the correct text string using distorted or noisy text images to distinguish between automated programs and real humans \cite{txt-captcha-1,txt-captcha-2,txt-captcha-3}. Image-based CAPTCHA synthesizes the logical differences between humans and machines through image semantic understanding \cite{img-captcha-1,img-captcha-2}. For example, Tencent's VTT\cite{tencent-vtt} uses style migration in conjunction with 3D shapes to generate check images. Google's reCAPTCHA\cite{google-recaptcha} uses adversarial perturbations to interfere with AI's recognition of images to distinguish humans from bots. CAPTCHA based on phonetic or biological information uses voiceprint or timbre to differentiate between human and synthetic speech \cite{audio-captcha-1}, which is less common than images and text. 


CATPCHAs based on images, text, and sounds are significant because these verification methods can provide an obvious target for the screening object to process. The AI robot can be purposefully simulated to bypass these filters because of their strong willingness \cite{easy-not-secure}. For example, Deng et al. \cite{llm-captcha-1} exploited the cross-domain logic capabilities of LLMs to bypass image understanding tasks. Hossen \cite{recaptcha-yolov3} uses YOLOv3 \cite{yolov3} to locate elements in reCAPTCHA v2. Wang \cite{txt-rcnn-att-chinese} prefers the word obfuscation-generating units combined with Recurrent Neuronal Networks (RNN) \cite{RNN}, Convolutional Neural Networks (CNN) \cite{CNN}, and attention mechanisms \cite{ATT} to achieve Chinese validator bypass. Due to the vulnerability of explicit CAPTCHA to attacks, CAPTCHA based on implicit user behavior verification has been chosen as a new type of verifier.

The implicit nature of the user behavior CAPTCHA is reflected in the black-box nature, including the unnoticeable, unknowable, and unrepeatable attributions in detection. Mouse2Vec \cite{Mouse2Vec} uses the Transformer self-supervised framework for learning semantic representations of mouse behavior. ReMouse \cite{ReMouse} provides novel real-world mouse dynamics datasets and finds that the irreducible nature of human manipulation can be used to circumvent replayed machine simulation behavior. Acien\cite{phone-traj} uses RNN for gesture recognition to realize user touch behavior detection of smartphones. Jin\cite{jin-mouse-traj} uses CNN and RNN to distinguish human and machine mouse trajectories. T-Detector\cite{T-Detector} uses RNN and CNN to model human-computer operational differences in gaming scenarios and finds that humans have more ineffective activities. As a long-term detection process, the mouse track CAPTCHA is considered to have a certain degree of review and correction capabilities. This makes the attack robots facing it relatively more complicated and requires considering the accumulation of multiple factors.

The invisibility and complexity of user behavior CAPTCHAs make mouse trajectory attacks in their infancy. Existing methods focus on using distribution fitting to generate behaviors of fake humans to bypass the detection. BeCAPTCHA-Mouse\cite{mt-becaptcha} uses Generative Adversarial Networks (GAN) \cite{GAN2} to generate mouse trajectory distributions that mimic those of humans. Folch\cite{mt-captcha-3} uses a hybrid mechanism of multiple straight lines and curves to simulate and detect the robot mouse operation trajectory. SapiAgent \cite{mt-SapiAgent} uses an auto-encoder to simulate human operations. CC-Net \cite{cc-net}designed a set of image- and text-based multimodal network-generated basic sequences of computer operations and outperformed on the MiniWob++ \cite{MiniWob} test. Tsingenopoulos \cite{mt-captcha-rl-2} designed an automated web browser based on Reinforcement Learning (RL) \cite{RL} to bypass the behavioral scoring mechanism of reCAPTCHA v3, and found that if humans are involved in initiating the browsing, the subsequent non-human operating agent is extremely difficult to detect.

Summarily, among all CAPTCHAs, user behavior detection can provide the website with the greatest protection against machine abuse. Although the existing solutions to bypass user behavior detection mostly use adversarial generation to promote robots to imitate humans, there are still some problems in track generation: 1) \textbf{Anthropomorphic Stylization}. The non-repeatability of human operations found by ReMouse \cite{ReMouse}, the ineffective human operation characteristics found by T-Detector \cite{T-Detector}, and the human hot-start bypassing found by Tsingenopoulos \cite{mt-captcha-rl-2}, all show that there is still room for improvement in existing mouse track generation schemes. Thus, the new type of mouse trajectory generation needs to imitate the randomness of human operations and the historical styles of different humans to form an attack scheme with inconspicuous differences. 2) \textbf{Practical Testing Limitationn}. Although some solutions have passed the reCAPTCHA experiment, they still need to be more widely verified in a variety of commercial CAPTCHAs.

\subsection{Generative Artificial Intelligence}

GAI creates creative, hard-to-code, clear, persuasive, and relatively versatile text or visual output based on large amounts of training data, augmenting the capabilities of existing human workers by increasing productivity and bringing greater efficiency to repetitive editing tasks \cite{GAI-product-effect}. Modern GAI tasks mainly focus on fields like sequences (video, text, audio), images/graphics, and chemistry/biomedicine, aiming to generate working modes or result distributions that are close enough to humans \cite{GAI-defination}. These tasks mainly rely on four frameworks: Encoder-Decoder \cite{AutoEncoder, VAE, DAE, OpenVoice}, GAN \cite{GAN2, GAN, CycleGAN, StyleGAN}, Transformer \cite{ATT, ViT, GPT, Dall-E}, and Diffusion Network \cite{DiffusionNet, DDPM, AlphaFold3}. These four architectures can be grouped according to the global distribution and local context of modeling. Among them, Encoder-Decoder and GAN are typical global sampling, which advocate representing the input as an independent distribution and resampling it as new data. While Transformer and Diffusion Networks follow local context sampling, which cumulatively obtains new data whose elements are related to each other through time-step changes.

As discussed in \cref{sec:relwk-captcha}, existing mouse trajectory generation methods mainly employ GANs and Encoder-Decoder architectures. These architectures are prone to biases in local features, resulting in identification as robotic behavior. And we believe that Transformer and Diffusion Networks can correct such local disparities. Therefore, we will focus on discussing the current state of Transformer and Diffusion Networks here.

Although both Transformer and Diffusion Networks reason through context, there is a dimensional difference. Transformer performs contextual vacancy reduction more through spatially consistent logic. For example, ViT \cite{ViT} and DALL-E \cite{Dall-E} can generate scene-dependent images from the positional encoding and pixel content of image patches. GPT \cite{GPT} and LLaMA \cite{llama} are good at generating subsequent words with the help of conditional transfer probabilities from the preceding content of the text. While Transformers demonstrate efficient information-gathering capabilities, they still pose risks of forgetting in ultra-long, infinite, or cross-domain scenarios \cite{vit-gan-survey}. At the same time, because Transformer's original models are generally large and complex, it is difficult to balance its computational efficiency and accuracy \cite{vit-survey}. These requirements constrain the deployment of Transformer to low-resource computing devices, making the computational cost difficult to control.

Diffusion Network generates special results from noise by utilizing thermodynamic diffusion principles and their inverse processes on time slices \cite{DiffusionNet}. Compared to the Transformers, Diffusion Networks better represent the continuity of frames and states. For example, DDPM \cite{DDPM} implements a deep diffusion model fitting method for generating high-quality images of the same subject. AlphaFold3 \cite{AlphaFold3} utilizes a diffusion model to generate the folded spatial structure of a protein macromolecule. MedSegDiff \cite{MedSegDiff} has designed a DDPM-based U-Net \cite{u-net} architecture for segmenting regions in medical images. UniDiffuser \cite{UniDiffuser} presents a multi-distributed diffusion model for generating realistic text or images that rival customized large-scale Transformer capabilities while maintaining efficiency, demonstrating the potential of Diffusion Networks. Current challenges in Diffusion Networks focus on the distribution, direction, process, and feedback controllability of generation \cite{difu-survey, v-difu-survey, difu-survey-2} so that researchers still have room for improvement in locally customized generation.